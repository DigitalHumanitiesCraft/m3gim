# M¬≥GIM Design-Entscheidungen

*Arbeitsversion ‚Äì Systematische Bearbeitung der offenen Fragen aus DESIGN.md*

---

## Methodik

Dieses Dokument bearbeitet die 13 offenen Fragen aus dem Design-Dokument. F√ºr jede Frage:
1. **Position A:** Empfohlene L√∂sung mit Begr√ºndung
2. **Position B:** Gegenposition oder Alternative
3. **Synthese:** Konkreter Handlungsvorschlag

---

## Archivfachliche Fragen

### Frage 2: Provenienz-Darstellung

> Wie visualisieren wir Entstehungskontext, ohne zu √ºberladen?

**Position A: Minimale Integration in Detailansicht**

Provenienz wird nur in der Detailansicht angezeigt, nicht in Listen oder Visualisierungen. Ein kompakter Block unter den Kernmetadaten:

```
PROVENIENZ
√úbernommen: 2015 vom Nachlass der K√ºnstlerin
Vorbesitz: Privatbesitz Ira Malaniuk, Z√ºrich
Bearbeitung: Erschlie√üung 2026 (Projekt M¬≥GIM)
```

*Begr√ºndung:* Provenienz ist f√ºr Quellenkritik wichtig, aber nicht f√ºr die t√§gliche Recherche. Die meisten Nutzenden interessiert "Was steht drin?", nicht "Wie kam es ins Archiv?".

**Position B: Provenienz als Filter-Dimension**

Provenienz k√∂nnte als Facette in der Objektsuche angeboten werden: "Zeige nur Objekte aus Privatbesitz" vs. "Zeige nur Objekte aus institutioneller √úberlieferung".

*Begr√ºndung:* F√ºr FF4 (Mobilit√§tsformen) k√∂nnte relevant sein, ob Dokumente aus der Grazer Zeit oder der Z√ºrcher Zeit stammen.

**Synthese:**

‚Üí **Phase 2:** Provenienz-Block in Detailansicht implementieren (minimaler Aufwand)
‚Üí **Phase 4 (optional):** Falls Daten vorhanden, Provenienz als Filter evaluieren

---

### Frage 3: Verkn√ºpfungstypen visuell unterscheiden

> Unterscheiden wir visuell zwischen agent/subject/location? ‚Üí Vorschlag: Icons (üë§/üèõÔ∏è/üìç/üé≠/üìÖ)

**Position A: Icons verwenden**

| Typ | Icon | Farbe |
|-----|------|-------|
| person | üë§ | Blau |
| institution | üèõÔ∏è | Grau |
| ort | üìç | Gr√ºn |
| werk | üé≠ | Orange |
| ereignis | üìÖ | Violett |

*Begr√ºndung:* Icons sind international verst√§ndlich, sparen Platz, und erm√∂glichen schnelles Scannen der Verkn√ºpfungsliste.

**Position B: Textuelle Kategorien ohne Icons**

Verkn√ºpfungen werden gruppiert dargestellt:

```
PERSONEN
- Ira Malaniuk (Vertragspartnerin)
- Rudolf Hartmann (Unterzeichner)

ORTE
- M√ºnchen (Vertragsort)
- Z√ºrich (Wohnort)
```

*Begr√ºndung:* Gruppierung ist √ºbersichtlicher als eine gemischte Liste mit Icons. Barrierefreier, da Icons von Screenreadern oft ignoriert werden.

**Synthese:**

‚Üí **Kombinieren:** Gruppierte Darstellung MIT Icons als visuellem Marker
‚Üí **Accessibility:** Icons mit aria-label versehen
‚Üí **Implementierung:** Gruppierung nach Typ, Icon vor jedem Eintrag

```
üë§ PERSONEN
   Ira Malaniuk (Vertragspartnerin)
   Rudolf Hartmann (Unterzeichner)

üìç ORTE
   M√ºnchen (Vertragsort)
   Z√ºrich (Wohnort)
```

---

## Visualisierungsfragen

### Frage 4: Netzwerk-Skalierung

> Bei 50+ Personen wird es un√ºbersichtlich. Clustering? Filter-Defaults?

**Position A: Progressive Disclosure mit Schwellenwert**

Default-Ansicht zeigt nur Personen mit **‚â•3 Dokumenten-Verbindungen** zu Malaniuk. Das reduziert die initiale Ansicht auf ~15-20 Kernpersonen (Karajan, B√∂hm, Werba, etc.). Nutzer k√∂nnen den Schwellenwert per Slider anpassen.

```
Verbindungsst√§rke: [‚ñ†‚ñ†‚ñ†‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°] 3+ Dokumente
                   ‚Üì
Zeige 18 von 52 Personen
```

*Begr√ºndung:* Die wichtigsten Beziehungen werden sofort sichtbar. "Einmal erw√§hnt" ist selten forschungsrelevant.

**Position B: Semantisches Clustering**

Personen werden nach Beziehungstyp gruppiert:
- Cluster "Dirigenten" (Karajan, B√∂hm, Knappertsbusch)
- Cluster "Kollegen" (Ludwig, Jurinac, Berry)
- Cluster "Agenten/Vermittler" (Taubman, etc.)

*Begr√ºndung:* Erm√∂glicht Einsichten in die Struktur des Netzwerks, nicht nur die St√§rke einzelner Verbindungen.

**Synthese:**

‚Üí **Phase 3:** Schwellenwert-Filter implementieren (technisch einfacher)
‚Üí **Phase 4:** Wenn Rollendaten ausreichend vorhanden, Clustering als Option anbieten
‚Üí **Konkret:** Default = 3+ Verbindungen, Slider von 1-10

---

### Frage 5: Timeline-Granularit√§t

> Tage vs. Monate vs. Jahre? Aggregation bei Zoom?

**Position A: Adaptive Granularit√§t (Semantic Zoom)**

Die Granularit√§t passt sich dem Zoom-Level an:

| Zoom-Level | Zeitspanne sichtbar | Granularit√§t | Darstellung |
|------------|---------------------|--------------|-------------|
| √úbersicht | 1919-1998 (79 Jahre) | Jahre | Balken pro Jahr |
| Mittlere Ansicht | 1945-1960 (15 Jahre) | Monate | Punkte pro Monat |
| Detail | 1958 (1 Jahr) | Tage | Einzelne Dokumente |

*Begr√ºndung:* Verhindert √úberladung auf hoher Ebene, erm√∂glicht Pr√§zision im Detail. Nutzer navigieren intuitiv durch Zoom.

**Position B: Fixe Jahres-Ansicht mit Drill-Down**

Timeline zeigt immer Jahre. Klick auf ein Jahr √∂ffnet Modal mit Monats-/Tagesansicht.

*Begr√ºndung:* Einfacher zu implementieren, konsistente Darstellung, keine komplexe Zoom-Logik.

**Synthese:**

‚Üí **Phase 3:** Starte mit fixer Jahres-Ansicht + Drill-Down Modal
‚Üí **Phase 4:** Wenn Zeit/Budget, Semantic Zoom nachr√ºsten
‚Üí **Begr√ºndung:** Jahres-√úbersicht deckt 80% der Anwendungsf√§lle ab (FF2: √§sthetische Entwicklung √ºber Karriere)

---

### Frage 6: Karten-Basemap

> Historische Karte oder moderne? Einfach (Leaflet) oder aufw√§ndig?

**Position A: Moderne Karte (Leaflet + OpenStreetMap)**

Schlichte, moderne Basemap mit neutralem Stil (z.B. CartoDB Positron). Fokus liegt auf den Datenpunkten, nicht auf der Karte selbst.

*Begr√ºndung:*
- Performant und offline-f√§hig (Tiles k√∂nnen gecached werden)
- Grenzen von 1945-1970 sind komplex (Nachkriegszeit, geteiltes Deutschland)
- Orte existieren heute noch, nur Grenzen haben sich ge√§ndert

**Position B: Historische Karte als Layer**

Zeitgen√∂ssische Karte (z.B. aus David Rumsey Collection) als optionaler Layer.

*Begr√ºndung:* F√ºr FF4 (Mobilit√§tsformen, erzwungene Migration) k√∂nnte der historische Kontext wichtig sein ‚Äì Lemberg lag 1944 nicht in der "Ukraine", sondern war Teil wechselnder Herrschaftsgebiete.

**Synthese:**

‚Üí **Phase 3:** Leaflet mit moderner Basemap (CartoDB Positron)
‚Üí **Phase 4 (optional):** Historischer Layer als Forschungsoption, wenn Bedarf vom KUG-Team best√§tigt
‚Üí **Begr√ºndung:** Moderne Karte ist neutral und lenkt nicht vom eigentlichen Inhalt ab

---

### Frage 7: Mobilit√§tsform-Encoding

> Ist Farbe das richtige visuelle Attribut, oder besser Linienart/Icons?

**Position A: Farbe als prim√§res Encoding**

| Mobilit√§tsform | Farbe | Hex |
|----------------|-------|-----|
| Erzwungen | Rot | #D32F2F |
| Geografisch | Gr√ºn | #2E7D32 |
| Bildung | Gelb | #ED6C02 |
| Lebensstil | Violett | #7B1FA2 |
| National | Blau | #1976D2 |

*Begr√ºndung:* Farbe ist das st√§rkste pr√§attentive Merkmal ‚Äì Unterschiede werden sofort wahrgenommen. Bei 5 Kategorien noch gut unterscheidbar.

**Position B: Linienart + Farbe kombiniert**

Zus√§tzlich zur Farbe:
- Erzwungen: gestrichelte Linie (Bruch)
- Geografisch: durchgezogene Linie (Kontinuit√§t)
- Bildung: gepunktete Linie (Entwicklung)

*Begr√ºndung:* Redundantes Encoding hilft bei Farbenblindheit (~8% der m√§nnlichen Bev√∂lkerung).

**Synthese:**

‚Üí **Farbe als prim√§res Merkmal** (visuell dominant)
‚Üí **Linienart als sekund√§res Merkmal** (Accessibility)
‚Üí **Tooltips** zeigen Mobilit√§tsform als Text
‚Üí **Legende** kombiniert alle drei Encodings

---

## Forschungsfragen

### Frage 9: Export-Formate

> Welche Datenformate braucht die Fachcommunity (CSV, RDF, Gephi)?

**Position A: CSV als universelles Format**

CSV-Export f√ºr gefilterte Ergebnisse. Spaltenstruktur entspricht der Objekttabelle + aufgel√∂ste Verkn√ºpfungen.

*Begr√ºndung:* CSV ist das "kleinste gemeinsame Vielfache" ‚Äì √∂ffnet in Excel, importierbar in jede Datenbank, maschinenlesbar.

**Position B: Spezialisierte Formate f√ºr Visualisierungstools**

- **Gephi (GEXF):** F√ºr Netzwerkanalyse
- **Palladio (JSON):** F√ºr Digital-Humanities-Workflows
- **GeoJSON:** F√ºr Karten-Weiterverarbeitung

*Begr√ºndung:* Die Fachcommunity arbeitet mit spezialisierten Tools. Ein CSV-Export erfordert manuelle Transformation.

**Synthese:**

‚Üí **Phase 2:** CSV-Export f√ºr Objektliste (einfach, universell)
‚Üí **Phase 3:** JSON-LD ist bereits vorhanden (RDF-kompatibel)
‚Üí **Phase 4:** Gephi-Export (GEXF) f√ºr Netzwerk, wenn Forschungsbedarf best√§tigt
‚Üí **Priorit√§t:** CSV > JSON-LD > GEXF > GeoJSON

---

### Frage 10: Mobilit√§tsform-Erfassung (bereits gel√∂st)

> Wie wird die Mobilit√§tsform bei Orts-Verkn√ºpfungen erfasst?

‚úì **Gel√∂st in Datenmodell v2.2:** Pr√§fix-Notation in Anmerkungsfeld `[mobilit√§t:erzwungen]`

‚Üí Workshop am 23.01. kl√§rt Erfassungsworkflow

---

## Technische Fragen

### Frage 11: Offline-F√§higkeit

> Bleibt das Prinzip "alles eingebettet" bei gr√∂√üeren Visualisierungen?

**Position A: Beibehaltung des Offline-First-Prinzips**

Alle Daten (JSON-LD, ~500KB) werden beim Laden eingebettet. Visualisierungen arbeiten clientseitig auf diesen Daten.

*Begr√ºndung:*
- Keine CORS-Probleme
- Funktioniert auch ohne Internetverbindung
- GitHub Pages hat keine Serverlogik
- 500KB sind bei modernen Verbindungen in <1s geladen

**Position B: Lazy Loading f√ºr Visualisierungen**

Grunddaten eingebettet, aber Visualisierungsdaten (z.B. Netzwerk-Edges, Koordinaten) werden bei Bedarf nachgeladen.

*Begr√ºndung:* Reduziert initiale Ladezeit. Nutzer, die nur die Objektsuche nutzen, laden keine Netzwerkdaten.

**Synthese:**

‚Üí **Offline-First beibehalten** f√ºr Kernfunktionen (Suche, Filter, Detailansicht)
‚Üí **Lazy Loading** f√ºr Visualisierungen als Option, aber nicht notwendig bei 436 Records
‚Üí **Entscheidung:** Bei aktuellem Datenvolumen kein Handlungsbedarf

---

### Frage 12: Performance bei 4000 Records

> 436 Records sind unproblematisch. Was bei 4000?

**Position A: Kein Problem mit modernem JavaScript**

Vanilla JS mit modernen APIs (Array.filter, Map, Set) verarbeitet 4000 Records in <50ms. Die Rendering-Grenze liegt bei ~10.000 DOM-Elementen gleichzeitig.

*Begr√ºndung:*
- Filter/Suche: O(n) ist bei 4000 kein Problem
- Rendering: Pagination oder Virtual Scrolling erst ab ~1000 gleichzeitig sichtbaren Karten n√∂tig
- Visualisierungen: D3.js handhabt 4000 Datenpunkte problemlos

**Position B: Pr√§ventive Optimierung**

- Pagination einf√ºhren (20-50 Ergebnisse pro Seite)
- Such-Index mit Fuse.js oder Lunr.js vorberechnen
- Web Workers f√ºr Filterung

*Begr√ºndung:* Pr√§ventiv optimieren ist einfacher als reaktiv refactoren.

**Synthese:**

‚Üí **Aktuell:** Pagination ist bereits implementiert (MVP)
‚Üí **Bei Bedarf:** Virtual Scrolling nachziehen (Intersection Observer API)
‚Üí **Kein** pr√§ventiver Such-Index n√∂tig ‚Äì Volltextsuche √ºber 4000 Records ist in <100ms machbar
‚Üí **Entscheidung:** Erst optimieren, wenn messbare Probleme auftreten

---

### Frage 13: D3.js vs. Observable Plot

> Welche Bibliothek f√ºr Timeline/Netzwerk?

**Position A: D3.js f√ºr alles**

D3.js ist der De-facto-Standard f√ºr datengetriebene Visualisierungen. Volle Kontrolle √ºber jeden Aspekt.

| Aspekt | D3.js |
|--------|-------|
| Netzwerk | Force-directed Layout (d3-force) |
| Timeline | Scales + Axes (d3-scale, d3-axis) |
| Karte | Integration mit Leaflet m√∂glich |
| Lernkurve | Steil, aber gut dokumentiert |
| Bundle-Size | ~80KB minified |

*Begr√ºndung:* Ein Framework f√ºr alle Visualisierungen bedeutet konsistentes Code-Design und weniger Abh√§ngigkeiten.

**Position B: Observable Plot f√ºr Timeline, D3.js f√ºr Netzwerk**

Observable Plot ist eine h√∂here Abstraktion √ºber D3, optimiert f√ºr statistische Visualisierungen (Balken, Linien, Zeitreihen).

| Aspekt | Observable Plot |
|--------|-----------------|
| Timeline | Sehr einfach (Plot.plot mit marks) |
| Netzwerk | Nicht geeignet |
| Lernkurve | Flach |
| Bundle-Size | ~50KB |

*Begr√ºndung:* F√ºr die Timeline brauchen wir keine D3-Flexibilit√§t. Observable Plot produziert in 10 Zeilen, was D3 in 100 macht.

**Synthese:**

‚Üí **D3.js f√ºr Netzwerk** (unverzichtbar f√ºr Force-Layout)
‚Üí **Observable Plot f√ºr Timeline** (schnellere Implementierung, wartbarer Code)
‚Üí **Leaflet f√ºr Karte** (Spezialbibliothek, besser als D3-Geo)
‚Üí **Begr√ºndung:** Pragmatismus ‚Äì die richtige Bibliothek f√ºr den Job

---

## Zusammenfassung der Entscheidungen

| Frage | Entscheidung | Phase |
|-------|--------------|-------|
| Provenienz | Minimale Darstellung in Detailansicht | 2 |
| Verkn√ºpfungs-Icons | Gruppierung + Icons mit aria-label | 2 |
| Netzwerk-Skalierung | Schwellenwert-Filter (Default: 3+ Verbindungen) | 3 |
| Timeline-Granularit√§t | Fixe Jahres-Ansicht + Drill-Down Modal | 3 |
| Karten-Basemap | Leaflet + CartoDB Positron (modern, neutral) | 3 |
| Mobilit√§tsform-Encoding | Farbe prim√§r + Linienart sekund√§r | 3 |
| Export-Formate | CSV ‚Üí JSON-LD ‚Üí GEXF (nach Priorit√§t) | 2-4 |
| Offline-F√§higkeit | Beibehalten, kein Handlungsbedarf | - |
| Performance 4000 | Erst bei Bedarf optimieren | - |
| Visualisierungs-Bibliotheken | D3.js (Netzwerk) + Observable Plot (Timeline) + Leaflet (Karte) | 3 |

---

*Erstellt: 2026-01-18*
